{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da4e64d-5333-415e-b2ec-c52343efe934",
   "metadata": {},
   "source": [
    "# Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d6947-fb8d-4009-bdde-2be96478eef2",
   "metadata": {},
   "source": [
    "## 1.What is maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913e38e-2fc0-493c-a8bc-fd1d4921e91c",
   "metadata": {},
   "source": [
    "Maximum likelihood estimation (MLE) is a **method** to estimate econometric models. MLE first assumes a parametric distribution of y|x, and then maximize the observed joint probability density function with respect to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cd172-8f8a-41a3-86e5-e20414dbe7e6",
   "metadata": {},
   "source": [
    "As an example, let's assume a simple linear regression model where\n",
    "\n",
    "$$y=\\beta_0 + \\beta_1 x + u$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60546e-7d36-4b8a-ab42-5d0c8b90b130",
   "metadata": {},
   "source": [
    "We first assume that conditional on X=x, y satisfies a normal distribution with mean equal to $\\beta_0 + \\beta_1 x$, and variance equal to $\\sigma^2$. In this setup, we are using the same assumptions as OLS (although this is not necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d952faf-5f28-4212-8c27-5253e599554f",
   "metadata": {},
   "source": [
    "With the assumptions, we can explicitly write down the probability density function of one observation \n",
    "\n",
    "$$ f(y_i|x_i) = \\phi(\\frac{y_i-\\beta_0-\\beta_1x}{\\sigma}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95bdf3f-fe9c-4ce1-b9f3-b7c3044f659e",
   "metadata": {},
   "source": [
    "And with Gauss-Markov assumption 3 - $u_i$ are independently distributed. We have the joint probability (likelihood) function of all observations as\n",
    "\n",
    "$$\\Pi_i f(y_i|x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9320a-3d49-4b0a-b011-406bca5d486d",
   "metadata": {},
   "source": [
    "And we maximize this joint probability with respect to all the parameters\n",
    "\n",
    "$$\\max_{\\beta_0, \\beta_1, \\sigma} \\Pi_i f(y_i|x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a611937-08af-46f8-a0ce-bab93ddb418d",
   "metadata": {},
   "source": [
    "There is one more adjustment we can make to simplify the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6249964-2eb8-49af-9bcf-f53f9aa65bff",
   "metadata": {},
   "source": [
    "Because 1) a maximizing a production is more difficult than maximizing a summation, and 2) optima preserves under strictly increasing transformation of the objective function, we take logarithm of the objective function and solve the following log-likelihood maximization problem\n",
    "\n",
    "$$\\max_{\\beta_0, \\beta_1, \\sigma} \\Sigma_i lnf(y_i|x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09db11-18d8-4e85-b89a-d1ca1935bbd0",
   "metadata": {},
   "source": [
    "> Advantages of maximimum likelihood estimation\\\n",
    "**More flexible** - can be used with any distribution and any functional form\\\n",
    "**Easy to implement** when you known the probability of y given x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8306e-afe2-40dd-ac19-d51de326f5d7",
   "metadata": {},
   "source": [
    "## 2.Another Example - Probit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8199c5fa-ad3a-4303-b3da-0fc3c897b433",
   "metadata": {},
   "source": [
    "Assume we want to estimate the effect of hours of study on the odds of getting an A in ECO301.\n",
    "\n",
    "1. Specify a linear regression model\n",
    "2. Is there any issue with this linear regression model? \n",
    "3. How can you restrict the value of $\\hat{y}$ to be between 0 and 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f0183-881a-49f7-af6b-21f099559013",
   "metadata": {},
   "source": [
    "A probit model assumes\n",
    "$$P(y=1) = \\Phi(x^T\\beta)$$\n",
    "and \n",
    "$$P(y=0) = 1-\\Phi(x^T\\beta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd21a078-ec09-48fe-ab50-3b053fb7d7c4",
   "metadata": {},
   "source": [
    "therefore the likelihood function $f(y_1, y_2,...\\mid X, \\beta)$ can be written as\n",
    "\n",
    "$$\\Pi \\Phi_i(x_i^T\\beta)\\mathcal{1}(y=1)\\times(1-\\Phi_i(x_i^T\\beta))\\mathcal{1}(y=0)$$\n",
    "\n",
    "where $\\Phi()$ is normal cumulative density function. By taking the logarithm, the objective function to be maximized is\n",
    "\n",
    "$$\\sum_i ln\\Phi_i(x_i^T\\beta)\\mathcal{1}(y=1)+ln\\Phi_i(-x_i^T\\beta)\\mathcal{1}(y=0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b025e-7894-4a2a-a527-aa2c28fac20a",
   "metadata": {},
   "source": [
    "## 3.Implement Probit model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e0b9d7-dc53-447c-a2d5-1f07a329f20c",
   "metadata": {},
   "source": [
    "Here we provide a new source of data - sample datasets from the statsmodels package.You can find a full list of sample datasets [here](https://www.statsmodels.org/stable/datasets/index.html). The spector dataset contains experimental data on the effectiveness of the personalized system of instruction (PSI) program.\n",
    "\n",
    "Grade - binary variable indicating whether or not a student's gradeimproved.  1 indicates an improvement. \\\n",
    "TUCE  - Test score on economics test \\\n",
    "PSI   - participation in program \\\n",
    "GPA   - Student's grade point average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b5d803-991a-4986-939f-29fa704a2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.api as sm\n",
    "\n",
    "ds = sm.datasets.spector.load_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de0c247-fce7-42bf-bf3e-ebd3d899a60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>TUCE</th>\n",
       "      <th>PSI</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.66</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.89</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.28</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.92</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GPA  TUCE  PSI  GRADE\n",
       "0  2.66  20.0  0.0    0.0\n",
       "1  2.89  22.0  0.0    0.0\n",
       "2  3.28  24.0  0.0    0.0\n",
       "3  2.92  12.0  0.0    0.0\n",
       "4  4.00  21.0  0.0    1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f6b7fa-9314-4e47-b373-545bfcf96faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400588\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>GRADE</td>      <th>  No. Observations:  </th>  <td>    32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>Probit</td>      <th>  Df Residuals:      </th>  <td>    28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 26 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.3775</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:24:46</td>     <th>  Log-Likelihood:    </th> <td> -12.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -20.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.001405</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -7.4523</td> <td>    2.542</td> <td>   -2.931</td> <td> 0.003</td> <td>  -12.435</td> <td>   -2.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GPA</th>       <td>    1.6258</td> <td>    0.694</td> <td>    2.343</td> <td> 0.019</td> <td>    0.266</td> <td>    2.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TUCE</th>      <td>    0.0517</td> <td>    0.084</td> <td>    0.617</td> <td> 0.537</td> <td>   -0.113</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PSI</th>       <td>    1.4263</td> <td>    0.595</td> <td>    2.397</td> <td> 0.017</td> <td>    0.260</td> <td>    2.593</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  GRADE   No. Observations:                   32\n",
       "Model:                         Probit   Df Residuals:                       28\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 26 Apr 2022   Pseudo R-squ.:                  0.3775\n",
       "Time:                        15:24:46   Log-Likelihood:                -12.819\n",
       "converged:                       True   LL-Null:                       -20.592\n",
       "Covariance Type:            nonrobust   LLR p-value:                  0.001405\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -7.4523      2.542     -2.931      0.003     -12.435      -2.469\n",
       "GPA            1.6258      0.694      2.343      0.019       0.266       2.986\n",
       "TUCE           0.0517      0.084      0.617      0.537      -0.113       0.216\n",
       "PSI            1.4263      0.595      2.397      0.017       0.260       2.593\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "reg = smf.probit(\"GRADE~GPA+TUCE+PSI\",data=df)\n",
    "res = reg.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a459b05-1833-425d-8de3-4efad8337779",
   "metadata": {},
   "source": [
    "### Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61b90f-d8db-488c-a878-5ccc9217c81a",
   "metadata": {},
   "source": [
    "**Pseudo R-squared** \\\n",
    "Recall that R-squared is a statistic generated in ordinary least squares (OLS) regression that is often used as a goodness-of-fit measure.  In OLS,\n",
    "\n",
    "$$R^2 = SSR/SST = 1- SSE/SST$$\n",
    "\n",
    "There are several approaches to thinking about R-squared in OLS:\n",
    "\n",
    "1. R-squared as explained variability\n",
    "2. R-squared as improvement from null model to fitted model. The denominator of the ratio can be thought of as the sum of squared errors from the null model – a model predicting the dependent variable without any independent variables. \n",
    "3. R-squared as the square of the correlation. R-squared is the square of the correlation between the model’s predicted values and the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea07030-af45-4eb0-ace5-ca79fe82e468",
   "metadata": {},
   "source": [
    "When analyzing data with a maximum likelihood method, an equivalent statistic that has all of the above meanings does not exist. Hence several pseudo R-squareds have been developed to assess some aspect of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c3e19-0e2b-4fe1-bb3d-28c2f0576890",
   "metadata": {},
   "source": [
    "For example, statsmodels reports the McFadden's pseudo-R-squared.\n",
    "$$R^2 = 1-\\frac{lnL_{full}}{lnL_{intercept}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90bb5c-a1fe-44fc-ab82-b7fc0f0a7fce",
   "metadata": {},
   "source": [
    "The log likelihood of the intercept model is treated as a total sum of squares, and the log likelihood of the full model is treated as the sum of squared errors. So this pseudo R-squared measures the improvement from the intercept-only model to the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e7d48-c463-43e2-8e8e-14e41dbd58bb",
   "metadata": {},
   "source": [
    "**Likelihood Ratio Test (LR) - MLE version of F test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689d1ba-d988-4196-b154-bf49ca49e474",
   "metadata": {},
   "source": [
    "LR-test utilizes the fact that $-2(lnL_{intercept} - lnL_{full}) \\sim \\chi^2(k)$ if $\\beta_1=\\beta_2=...=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69699265-66b5-43b3-93b9-3d98d4510f42",
   "metadata": {},
   "source": [
    "**coefficient**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb6eba-f825-4f20-a0c5-a3c77581815e",
   "metadata": {},
   "source": [
    "Interpretation of the coefficients in probit regression is not as straightforward as the interpretations of coefficients in linear regression. \n",
    "\n",
    "$$P(y=1) = \\Phi(x^T\\beta)$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\\frac{\\partial P(y=1)}{\\partial\\ x_1} = \\Phi(x^T\\beta)\\times \\beta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39ca6b-3c25-413a-bc49-13830a8c4bb8",
   "metadata": {},
   "source": [
    "The marginal effect of $x_1$ is not a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff46d9-98e7-4c41-9929-a86b368d788e",
   "metadata": {},
   "source": [
    "However, there are limited ways in which we can interpret the individual regression coefficients. \n",
    "\n",
    "1. A positive coefficient means that an increase in the predictor leads to an increase in the predicted probability.  A negative coefficient means that an increase in the predictor leads to a decrease in the predicted probability.\n",
    "2. **Average Marginal Effect** - We can first calculate the marginal effect for each observation and then calculate the average of all marginal effects.\n",
    "3. **Marginal Effect at the mean** - Alternatively, we can first calculate $\\bar{x}$ and substitutes its value into $\\Phi(.)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef77858-b505-4ee2-ac84-394d3e85eb53",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Load the **ncaa_rpi.csv** dataset from Coursesite. This dataset contains data on NCAA men's basketball teams. \n",
    "We are interestted in whether, once the previous year's post-season RPI (*postrpi_1*) is controlled for, does the pre-season RPI (*prerpi*) - which is supposed to add information on recruiting and player development - help to predict performance. \n",
    "\n",
    "Run a probit model using *tourney* - whether the team makes it to the NCAA tournament - as the dependent variable and *prerpi* as the independent variable of interest. Control for previous year's post-season RPI (*postrpi_1*), coach experience (*coachexper*), and winning percentage (*winperc*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14086a4-fc07-4352-940a-7104d6d46c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>conference</th>\n",
       "      <th>postrpi</th>\n",
       "      <th>prerpi</th>\n",
       "      <th>postrpi_1</th>\n",
       "      <th>postrpi_2</th>\n",
       "      <th>recruitrank</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>winperc</th>\n",
       "      <th>tourney</th>\n",
       "      <th>coachexper</th>\n",
       "      <th>power5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston College</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>ACC</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>97</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>70.58824</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston College</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>ACC</td>\n",
       "      <td>115</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>131</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>48.38710</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston College</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>ACC</td>\n",
       "      <td>114</td>\n",
       "      <td>223</td>\n",
       "      <td>244</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>48.48485</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boston College</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>ACC</td>\n",
       "      <td>249</td>\n",
       "      <td>102</td>\n",
       "      <td>161</td>\n",
       "      <td>204</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>21.87500</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clemson</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>ACC</td>\n",
       "      <td>104</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>176</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35.71429</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             team       year conference  postrpi  prerpi  postrpi_1  \\\n",
       "0  Boston College  2003-2004        ACC       19      37         44   \n",
       "1  Boston College  2009-2010        ACC      115      53         67   \n",
       "2  Boston College  2012-2013        ACC      114     223        244   \n",
       "3  Boston College  2015-2016        ACC      249     102        161   \n",
       "4         Clemson  2003-2004        ACC      104      90        125   \n",
       "\n",
       "   postrpi_2  recruitrank  wins  losses   winperc  tourney  coachexper  power5  \n",
       "0         55           97    24      10  70.58824        1          23       1  \n",
       "1        131          300    15      16  48.38710        0          27       1  \n",
       "2         65           69    16      17  48.48485        0          28       1  \n",
       "3        204           69     7      25  21.87500        0          25       1  \n",
       "4        176           88    10      18  35.71429        0          28       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ncaa_rpi.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecedca92-2932-408e-823a-612654c3cd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>tourney</td>     <th>  R-squared:         </th> <td>   0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 26 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>1.40e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:24:55</td>     <th>  Log-Likelihood:    </th> <td> -195.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   336</td>      <th>  AIC:               </th> <td>   399.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   332</td>      <th>  BIC:               </th> <td>   414.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    0.4865</td> <td>    0.079</td> <td>    6.137</td> <td> 0.000</td> <td>    0.331</td> <td>    0.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prerpi</th>     <td>    0.0002</td> <td>    0.002</td> <td>    0.143</td> <td> 0.886</td> <td>   -0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postrpi_1</th>  <td>   -0.0031</td> <td>    0.001</td> <td>   -2.365</td> <td> 0.019</td> <td>   -0.006</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coachexper</th> <td>    0.0067</td> <td>    0.003</td> <td>    2.486</td> <td> 0.013</td> <td>    0.001</td> <td>    0.012</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>209.612</td> <th>  Durbin-Watson:     </th> <td>   1.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  22.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.187</td>  <th>  Prob(JB):          </th> <td>1.23e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.785</td>  <th>  Cond. No.          </th> <td>    503.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                tourney   R-squared:                       0.218\n",
       "Model:                            OLS   Adj. R-squared:                  0.211\n",
       "Method:                 Least Squares   F-statistic:                     30.78\n",
       "Date:                Tue, 26 Apr 2022   Prob (F-statistic):           1.40e-17\n",
       "Time:                        15:24:55   Log-Likelihood:                -195.61\n",
       "No. Observations:                 336   AIC:                             399.2\n",
       "Df Residuals:                     332   BIC:                             414.5\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.4865      0.079      6.137      0.000       0.331       0.642\n",
       "prerpi         0.0002      0.002      0.143      0.886      -0.003       0.003\n",
       "postrpi_1     -0.0031      0.001     -2.365      0.019      -0.006      -0.001\n",
       "coachexper     0.0067      0.003      2.486      0.013       0.001       0.012\n",
       "==============================================================================\n",
       "Omnibus:                      209.612   Durbin-Watson:                   1.952\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.618\n",
       "Skew:                           0.187   Prob(JB):                     1.23e-05\n",
       "Kurtosis:                       1.785   Cond. No.                         503.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = \"tourney ~ prerpi + postrpi_1 + coachexper\"\n",
    "reg_ols = smf.ols(formula, data=df)\n",
    "res_ols = reg_ols.fit()\n",
    "res_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d4b77e-4b8c-4252-a7ee-51de6ad3fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543789\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>tourney</td>     <th>  No. Observations:  </th>  <td>   336</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>Probit</td>      <th>  Df Residuals:      </th>  <td>   332</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 26 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1914</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:25:21</td>     <th>  Log-Likelihood:    </th> <td> -182.71</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -225.97</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.230e-18</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    0.0463</td> <td>    0.250</td> <td>    0.185</td> <td> 0.853</td> <td>   -0.444</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prerpi</th>     <td>   -0.0038</td> <td>    0.006</td> <td>   -0.663</td> <td> 0.507</td> <td>   -0.015</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postrpi_1</th>  <td>   -0.0071</td> <td>    0.005</td> <td>   -1.462</td> <td> 0.144</td> <td>   -0.017</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coachexper</th> <td>    0.0198</td> <td>    0.009</td> <td>    2.304</td> <td> 0.021</td> <td>    0.003</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                tourney   No. Observations:                  336\n",
       "Model:                         Probit   Df Residuals:                      332\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 26 Apr 2022   Pseudo R-squ.:                  0.1914\n",
       "Time:                        15:25:21   Log-Likelihood:                -182.71\n",
       "converged:                       True   LL-Null:                       -225.97\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.230e-18\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0463      0.250      0.185      0.853      -0.444       0.536\n",
       "prerpi        -0.0038      0.006     -0.663      0.507      -0.015       0.008\n",
       "postrpi_1     -0.0071      0.005     -1.462      0.144      -0.017       0.002\n",
       "coachexper     0.0198      0.009      2.304      0.021       0.003       0.037\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_probit = smf.probit(formula, data=df)\n",
    "res_probit = reg_probit.fit()\n",
    "res_probit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e0e1a2-e20d-4922-a452-a4c72048dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540474\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>tourney</td>     <th>  No. Observations:  </th>  <td>   336</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   332</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 21 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1964</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:53:27</td>     <th>  Log-Likelihood:    </th> <td> -181.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -225.97</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.087e-19</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    0.2228</td> <td>    0.433</td> <td>    0.515</td> <td> 0.607</td> <td>   -0.625</td> <td>    1.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prerpi</th>     <td>   -0.0098</td> <td>    0.011</td> <td>   -0.925</td> <td> 0.355</td> <td>   -0.030</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postrpi_1</th>  <td>   -0.0104</td> <td>    0.009</td> <td>   -1.218</td> <td> 0.223</td> <td>   -0.027</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coachexper</th> <td>    0.0300</td> <td>    0.015</td> <td>    2.059</td> <td> 0.040</td> <td>    0.001</td> <td>    0.059</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                tourney   No. Observations:                  336\n",
       "Model:                          Logit   Df Residuals:                      332\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 21 Apr 2022   Pseudo R-squ.:                  0.1964\n",
       "Time:                        12:53:27   Log-Likelihood:                -181.60\n",
       "converged:                       True   LL-Null:                       -225.97\n",
       "Covariance Type:            nonrobust   LLR p-value:                 4.087e-19\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2228      0.433      0.515      0.607      -0.625       1.071\n",
       "prerpi        -0.0098      0.011     -0.925      0.355      -0.030       0.011\n",
       "postrpi_1     -0.0104      0.009     -1.218      0.223      -0.027       0.006\n",
       "coachexper     0.0300      0.015      2.059      0.040       0.001       0.059\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_logit = smf.logit(formula, data=df)\n",
    "res_logit = reg_logit.fit()\n",
    "res_logit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cfa19-8c84-4e09-87d3-1cb4daf00f51",
   "metadata": {},
   "source": [
    "## 4.More flexible Python implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca6010-bc78-469b-8c8e-538ca1fe5a3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Generic MLE for Probit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698cf148-85fd-43bf-978c-204b1dff4f9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff126d1f-80e4-47db-b023-a9cdfc773f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4413e1-63b5-4131-96af-88825c09713c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/hphk8qzd0hd322w0ywqljvgh0000gn/T/ipykernel_85232/1661464457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "ds = sm.datasets.spector.load_pandas()\n",
    "X = sm.add_constant(data.exog)\n",
    "y = data.endog "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b7175-1abb-4965-aa15-052498dfcb97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build Objective function\n",
    "\n",
    "To provide your own objective function, you simply need to **overwrite** the `loglike` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd66418-027e-448a-9c56-36287c4cb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08dd5fa-8ebf-4438-9ed0-94f80755bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benx/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "endog = df[\"tourney\"]\n",
    "exog = df[[\"prerpi\",\"postrpi_1\",\"coachexper\"]]\n",
    "exog = sm.add_constant(exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a53171-dc0a-466c-95e6-55b041c3fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProbit(GenericLikelihoodModel):\n",
    "    def loglike(self, params): # 2 inputs: data, parameters\n",
    "        X = self.exog\n",
    "        y = self.endog\n",
    "        q = 2 * y - 1\n",
    "        return stats.norm.logcdf(X@params*q).sum() # returns the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84563b-76ea-498a-a3d5-c09f61a5a86d",
   "metadata": {},
   "source": [
    "MyProbit is a self-defined class that inherit the `GenericLikelihoodModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0813133-b465-4816-97d7-d9e5ebc802d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83fc2f7-febc-4f60-b4c8-dac3b0e9f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549675\n",
      "         Iterations: 125\n",
      "         Function evaluations: 222\n"
     ]
    }
   ],
   "source": [
    "res = MyProbit(endog=endog, exog=exog).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a3e0af-05a6-49bd-9700-49e017804396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MyProbit Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>tourney</td>      <th>  Log-Likelihood:    </th> <td> -184.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>MyProbit</td>      <th>  AIC:               </th> <td>   377.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   392.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 26 Apr 2022</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>15:27:15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   336</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   332</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    0.5439</td> <td>    0.252</td> <td>    2.162</td> <td> 0.031</td> <td>    0.051</td> <td>    1.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prerpi</th>     <td>   -0.0047</td> <td>    0.006</td> <td>   -0.801</td> <td> 0.423</td> <td>   -0.016</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postrpi_1</th>  <td>   -0.0075</td> <td>    0.005</td> <td>   -1.535</td> <td> 0.125</td> <td>   -0.017</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coachexper</th> <td>    0.0052</td> <td>    0.009</td> <td>    0.611</td> <td> 0.541</td> <td>   -0.011</td> <td>    0.022</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               MyProbit Results                               \n",
       "==============================================================================\n",
       "Dep. Variable:                tourney   Log-Likelihood:                -184.69\n",
       "Model:                       MyProbit   AIC:                             377.4\n",
       "Method:            Maximum Likelihood   BIC:                             392.7\n",
       "Date:                Tue, 26 Apr 2022                                         \n",
       "Time:                        15:27:15                                         \n",
       "No. Observations:                 336                                         \n",
       "Df Residuals:                     332                                         \n",
       "Df Model:                           3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5439      0.252      2.162      0.031       0.051       1.037\n",
       "prerpi        -0.0047      0.006     -0.801      0.423      -0.016       0.007\n",
       "postrpi_1     -0.0075      0.005     -1.535      0.125      -0.017       0.002\n",
       "coachexper     0.0052      0.009      0.611      0.541      -0.011       0.022\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9230ec-fcb1-44d6-bd0d-d66f7092bc0c",
   "metadata": {},
   "source": [
    "### 5.Extra: Optimization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553c431-eac1-4943-a354-6ec8fbc14747",
   "metadata": {},
   "source": [
    "In Python, we can easily find the local minimum of a scalar function with multiple variables using **scipy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14ea99c3-ad83-4de0-b71e-8f8db9120405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab79226-d9f2-4bc3-8ece-68695c55f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c69d94-3449-4c98-9afc-9112a0494a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return 2*x**2+x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00b5a3a-28a8-46a0-bd1c-9b72aec4d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 1.875\n",
       "    nfev: 28\n",
       "     nit: 24\n",
       " success: True\n",
       "       x: -0.2499999925800001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize_scalar(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8599ff-0579-4a31-93dd-d7a153e36d27",
   "metadata": {},
   "source": [
    "As a starting point, we need to define the objective function. This function should take the target parameters as its first argument, and there can be other arguments as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367349b3-a44d-4f5b-a848-b99a5d8ae49c",
   "metadata": {},
   "source": [
    "Let's copy and past the `loglike` function and detach it from the MyProbit class by replacing the `self` argument with data. In addition, we add a `-` sign to the return value, so that we convert the maximization problem to a minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1665480f-a287-427a-920b-f970bad79ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(params, data): # 2 inputs: data, parameters\n",
    "        X = sm.add_constant(data.exog)\n",
    "        y = data.endog\n",
    "        q = 2 * y - 1\n",
    "        return -stats.norm.logcdf(X@params*q).sum() # returns the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1fb2d13-2170-4664-abb0-3f4d0cbfd0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benx/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "res = minimize(loglike, x0=np.array([0,0,0,0]), args=(ds))\n",
    "# args provide other arugments to the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e41d1ce5-0ede-46c8-9d04-b395819724e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.45231082,  1.62581032,  0.05172852,  1.42633244])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
