{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6823aee8-d595-42ad-90c1-e44650c6102b",
   "metadata": {},
   "source": [
    "# 9 Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a968805-d8ae-4e94-b2b6-ef208543c5cc",
   "metadata": {},
   "source": [
    "## 1 What is Hypothesis Test\n",
    "\n",
    "The goal of analyzing a dataset (sample) is to make inference about **population parameters**. For example, we've learned how to obtain **point estimators - $\\hat{\\beta}$**. These estimators are used to infer the population parameters of interest - $\\beta$.\n",
    "\n",
    "**Hypothesis testing** is a different way to make inferences, whereby an analyst first make an assumption (called **null hypothesis**) regarding one(or several) population parameter(s), and then prove - by contradiction -  if we should reject or accept the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff751770-d52e-47e0-b61d-cb44343ad940",
   "metadata": {},
   "source": [
    "## 2 The Most Famous Example - t-Test\n",
    "\n",
    "t-test (aka significance test) is the most famous hypothesis test in econometrics. The test is used to infer if the population coefficient $\\beta=0$. In other words, we want to test whether there is any relation at all between the dependent variable y and a regressor $x_j$. In the standard setup, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb05bd-31bd-43aa-ab6e-9fafb0f175d0",
   "metadata": {},
   "source": [
    "$$H_0: \\beta_j=0$$\n",
    "$$H_1: \\beta_j\\neq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c239d-b0eb-47fc-9f7b-bbed236fa2d6",
   "metadata": {},
   "source": [
    "### Reasoning Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46780021-29d0-48af-96f3-eb2539b4de5f",
   "metadata": {},
   "source": [
    "If Gauss-Markov assumptions hold, we have $\\hat{\\beta_j}\\sim N(\\beta_j, \\sigma_{\\hat{\\beta_j}}^2)$ by central limit theorem. Hence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bacde0-e9b9-4d83-8bff-62ab8f96aa27",
   "metadata": {},
   "source": [
    "$$z_{\\hat{\\beta_j}}\\equiv \\frac{\\hat{\\beta_j}-\\beta_j}{\\sigma_{\\hat{\\beta_j}}} \\sim N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182ab3a-37b2-4a72-96f5-00302d8456f2",
   "metadata": {},
   "source": [
    "However, there is one small problem. Recall what is the formula for $\\sigma_{\\hat{\\beta_j}}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc1122-9f6b-4517-951e-2394ae4d1351",
   "metadata": {},
   "source": [
    "$$Var(\\hat{\\beta_j}) = \\frac{\\sigma^2}{nVar(x_j)}*\\frac{1}{1-R_j^2}$$\n",
    "$$\\sigma_{\\hat{\\beta_j}} = \\sqrt{Var(\\hat{\\beta_j})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5a963-703f-4b12-ab94-df8193036d23",
   "metadata": {},
   "source": [
    "In order to calculate $\\sigma_{\\hat{\\beta_j}}$, we need to know the population variance of $u$ -- $\\sigma^2$. But usually $\\sigma^2$ is unknown. \n",
    "\n",
    "If we replace $\\sigma^2$ with its sample estimate $s^2 = \\frac{\\sum \\hat{u}^2}{n-k-1}$, the estimated standard deviation of $\\hat{\\beta_j}$ is called the **standard error** of $\\hat{\\beta_j}$. And a new distribution - t-distribution - is derived for this estimated version of z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a469d41-043d-4e0b-86ef-73ca37251a09",
   "metadata": {},
   "source": [
    "$$t_{\\hat{\\beta_j}}\\equiv \\frac{\\hat{\\beta_j}-\\beta_j}{s.e.(\\hat{\\beta_j})} \\sim t(n-k-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86365c-e2ec-4541-a67e-1be3ee0b3b2f",
   "metadata": {},
   "source": [
    "### Reasoning Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421b7b0-cc92-447a-b011-75bac87b4262",
   "metadata": {},
   "source": [
    "If $\\beta_j = 0$, we can plug 0 into the t formula and obtain the t-statistic.\n",
    "$$t_{\\hat{\\beta_j}}\\equiv \\frac{\\hat{\\beta_j}}{s.e.(\\hat{\\beta_j})} \\sim t(n-k-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694bb22-4810-4d5f-9d88-c79c21db3e73",
   "metadata": {},
   "source": [
    "### Reasoning Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6599ee-4e38-44eb-9aa6-a68adeaa0b15",
   "metadata": {},
   "source": [
    "If $t_{\\hat{\\beta_j}}~t(n-k-1)$, then we can calculate $2*P(t>|t_{\\hat{\\beta_j}}|)$ according to the t distribution. The reason for using absolute value is that (1) t-distribution is symmetric, and (2) we want to know the probability of an extreme value, i.e. either a large value or a small value.\n",
    "\n",
    "If this $p-value$ is too low (usually compared with 3 benchmarks - 0.1, 0.05, 0.01), we claim that the null hypothesis is not very likely to be true. We reject the null hypothesis, and conclude that $\\beta_j$ is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2530dd7-5ba7-4bb6-a2b2-adcd2dca4cf3",
   "metadata": {},
   "source": [
    "### Python Implementation 1 - smf package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d71b8-fbc3-43de-8140-b8f697aa95ac",
   "metadata": {},
   "source": [
    "Specification\n",
    "$$ln(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 tenure +u$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b8b3cf-1806-4854-bddc-7d1e1bf93466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept     2.729230\n",
      "educ         12.555246\n",
      "exper         2.391437\n",
      "tenure        7.133070\n",
      "dtype: float64\n",
      "Intercept    0.01\n",
      "educ         0.00\n",
      "exper        0.02\n",
      "tenure       0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "df = woo.data(\"wage1\")\n",
    "res = smf.ols(\"np.log(wage) ~ educ + exper + tenure\", data=df).fit()\n",
    "print(res.tvalues)\n",
    "print(res.pvalues.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba00d9a-479c-4b65-a608-eb7ee4ccec9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(wage)</td>   <th>  R-squared:         </th> <td>   0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   80.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 29 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>9.13e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:11:20</td>     <th>  Log-Likelihood:    </th> <td> -313.55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   635.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   522</td>      <th>  BIC:               </th> <td>   652.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2844</td> <td>    0.104</td> <td>    2.729</td> <td> 0.007</td> <td>    0.080</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0920</td> <td>    0.007</td> <td>   12.555</td> <td> 0.000</td> <td>    0.078</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0041</td> <td>    0.002</td> <td>    2.391</td> <td> 0.017</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0221</td> <td>    0.003</td> <td>    7.133</td> <td> 0.000</td> <td>    0.016</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.534</td> <th>  Durbin-Watson:     </th> <td>   1.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  20.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.021</td> <th>  Prob(JB):          </th> <td>2.84e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.977</td> <th>  Cond. No.          </th> <td>    135.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           np.log(wage)   R-squared:                       0.316\n",
       "Model:                            OLS   Adj. R-squared:                  0.312\n",
       "Method:                 Least Squares   F-statistic:                     80.39\n",
       "Date:                Tue, 29 Mar 2022   Prob (F-statistic):           9.13e-43\n",
       "Time:                        13:11:20   Log-Likelihood:                -313.55\n",
       "No. Observations:                 526   AIC:                             635.1\n",
       "Df Residuals:                     522   BIC:                             652.2\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2844      0.104      2.729      0.007       0.080       0.489\n",
       "educ           0.0920      0.007     12.555      0.000       0.078       0.106\n",
       "exper          0.0041      0.002      2.391      0.017       0.001       0.008\n",
       "tenure         0.0221      0.003      7.133      0.000       0.016       0.028\n",
       "==============================================================================\n",
       "Omnibus:                       11.534   Durbin-Watson:                   1.769\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               20.941\n",
       "Skew:                           0.021   Prob(JB):                     2.84e-05\n",
       "Kurtosis:                       3.977   Cond. No.                         135.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c322a-d31e-4aa2-9f5a-ed2b1f5eced8",
   "metadata": {},
   "source": [
    "> [df.apply()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) is a useful function that enables you to apply a function to each row of a dataframe (series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c972e-e430-4369-acfb-571e1866ee98",
   "metadata": {},
   "source": [
    "### Python Implementation 2 - Calculate Using Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0ecbc9-8d95-4b52-b1f3-df4a688cdf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.72923048, 12.55524558,  2.39143711,  7.13307039])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import patsy as pt\n",
    "y,X = pt.dmatrices(\"np.log(wage) ~ educ + exper + tenure\", data=df)\n",
    "b_h = np.linalg.inv(X.T@X)@X.T@y\n",
    "y_h = X@b_h\n",
    "u_h = y-y_h\n",
    "s2 = sum(u_h**2)/(X.shape[0]-X.shape[1]) \n",
    "vcov = s2*np.linalg.inv(X.T@X)\n",
    "bse = np.sqrt(np.diagonal(vcov))\n",
    "t = b_h[:,0]/bse # if you see some irregular results, try converting matrix to a vector (extrac the first column)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd433e6c-796d-4d76-8f4a-6d088d0214c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=2.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca56b7-2b9a-45d2-8c6c-bfca3124616e",
   "metadata": {},
   "source": [
    "P(t>|t|) = 1- P(t<|t|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9cf0d7-1e86-4f82-ad36-fb2f8ca5dcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.  , 0.02, 0.  ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability calculation in Python\n",
    "from scipy import stats\n",
    "p_gt_t = stats.t.cdf(np.abs(t),X.shape[0]-X.shape[1])#degrees of freedom = n-p\n",
    "p = (1 - p_gt_t)*2 \n",
    "p.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f69ba4-3d7a-473e-943b-90a4510d04c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006547382710030636"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "(1-stats.t.cdf(t,len(df)-3-1))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6753f-d352-4391-8b7b-f9262b27a4b3",
   "metadata": {},
   "source": [
    "## 9.3 Apply the Idea to Test Other Estimators\n",
    "\n",
    "Following the logic of the t-test - (1) find the distribution (2) plug in the hypothesis (3) find a probability - we can carry out a lot more hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b39c2-6474-4c8d-8fa2-0d8d2d9de73e",
   "metadata": {},
   "source": [
    "### 1 F-test\n",
    "\n",
    "$$H_0: \\beta_1=\\beta_2=\\dots=\\beta_k =0$$\n",
    "\n",
    "If Gauss-Markov assumptions are true, after plugging in the null hypothesis, we have\n",
    "$$F \\equiv \\frac{(SST-SS_{error})/k}{SS_{error}/(n-k-1)} \\sim F(k,n-k-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e6353-dfdc-46a8-9ffa-6ed27dca5628",
   "metadata": {},
   "source": [
    "$P(F>F_{stat})$ is the p-value for F. (Since F-distribution is not symmetric, and it is always positive, we do not use two-tail tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be39bcc6-a68c-4dcb-ad7b-2bac7b950204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.39091867158423"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.fvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7708231f-7d18-48c4-a4f2-400bdd1da84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.f_pvalue.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a389bdf-de22-4836-acaf-ac2940358b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.39091867158423"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "sst = res.centered_tss\n",
    "ssr = res.ssr\n",
    "F_num = (sst-ssr)/res.df_model\n",
    "F_denom = ssr/res.df_resid\n",
    "F = F_num/F_denom\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5790f1-9bfe-42a7-86ae-ae6b70ba70ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.f.cdf(F,res.df_model,res.df_resid)).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72f868-3c8d-45b9-84a1-26a553a4302e",
   "metadata": {},
   "source": [
    "### 2 More General F-Test\n",
    "\n",
    "F test can be generalized to test part of $\\beta$s. As an example, consider the following specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b2d0f-da16-4181-8fee-972441db4f40",
   "metadata": {},
   "source": [
    "$$ln(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 tenure +u$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edec32-63d3-41e2-86b9-e5abb1fe9d3e",
   "metadata": {},
   "source": [
    "Instead of assuming all parameters on independent variables are equal to 0, we assume **q** restrictions\n",
    "$$H_0: \\beta_2 = \\beta_3 =0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f988149-8d84-49ec-95ea-78beb82cf39a",
   "metadata": {},
   "source": [
    "With Gauss-Markov Assumptions and the null hypothesis, we have\n",
    "\n",
    "$$F \\equiv \\frac{(SS_{error}^r-SS_{error})/q}{SS_{error}/(n-k-1)} \\sim F(q,n-k-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73fac9-0f89-47b7-a951-7b5fd9e33594",
   "metadata": {},
   "source": [
    "where $SS_{error}^r$ is the sum of squared error (residual) from a restricted model\n",
    "$$ln(wage) = \\beta_0 + \\beta_1 educ+u$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba60867a-4781-43ea-86bc-bf0c627d725f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smf implementation\n",
    "hypotheses = [\"exper=0\",\"tenure=0\"]\n",
    "ftest = res.f_test(hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7dac49-b699-4a4a-aa0a-29345e195796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.68515733]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftest.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e32839c-58ba-4fa3-b936-ac9d9b916284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpval = ftest.pvalue\n",
    "fpval.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdade01b-17c9-4ea8-9c80-88004bab45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varify\n",
    "ssr = res.ssr\n",
    "res2 = smf.ols(\"np.log(wage)~educ\",data=df).fit()\n",
    "ssrr = res2.ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466d4d10-d114-4877-9ecb-5af039a86d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.685157328648856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstat = (ssrr-ssr)/2/(ssr/res.df_resid)\n",
    "fstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79ad05f-4974-47ef-b88f-084585c7c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpval = (1-stats.f.cdf(fstat,2,res.df_resid))\n",
    "fpval.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3898b1-ff3a-44fc-8500-71de0f351ac4",
   "metadata": {},
   "source": [
    "### 3 Even More General F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc915b5a-e16b-482e-88f4-1998fb487cb3",
   "metadata": {},
   "source": [
    "In the null hypothesis, we do not need to equate $\\beta_j$ to 0. We can use any form of linear combinations. For example, in model\n",
    "\n",
    "$$ln(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 tenure +u$$\n",
    "\n",
    "We can assume\n",
    "\n",
    "$$H_0: \\beta_1=0.3,\\text{ and }\\beta_2=\\beta_3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc769bf-d662-400e-bba3-9742211f0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = [\"exper=0\",\"exper+tenure=0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dda38aa-74a1-4c38-9136-027f9fb2543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F statistic = 404.07, and its p-value = 0.00\n"
     ]
    }
   ],
   "source": [
    "# smf\n",
    "hypothesis=[\"educ=0.3\",\"exper=tenure\"]\n",
    "ftest = res.f_test(hypothesis)\n",
    "fstat = ftest.statistic[0,0]\n",
    "fpval = ftest.pvalue\n",
    "print(\"F statistic = {:.2f}, and its p-value = {:.2f}\".format(fstat,fpval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f534e70-084b-4f4d-b892-f0e30282099b",
   "metadata": {},
   "source": [
    "We reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f76bda7-6032-465e-9ad7-839ac3dc0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = res.f_test([\"4*tenure = educ\",\"exper=0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76640fa8-09bd-470b-8b28-fc1c0fc33865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.76853997]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed29111a-03d3-4912-a463-b95e5aee5804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.02371631)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c19cd55-76de-4a2b-b8c3-b2b562036fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02371631]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-stats.f.cdf(f.statistic,2,len(df)-3-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbd111-c2dc-47c5-b44d-691a983c77b6",
   "metadata": {},
   "source": [
    "# Extra - Wald test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a5dec-7b34-4c5c-b4da-5bbc8a9e0e3b",
   "metadata": {},
   "source": [
    "The Wald test, due to Wald(1943), is the preeminent test for joint restrictions. The null and alternative hypotheses of the Wald test are written as\n",
    "\n",
    "$$H_0: R\\beta = q$$\n",
    "$$H_1: R\\beta \\neq q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcb809-7be1-43d4-ace2-133b693ebc63",
   "metadata": {},
   "source": [
    "where in the notation used here there are h restrictions, R is an $h\\times p$ matrix of full rank h. $\\beta$ is the $p\\times 1$ parameter vector, q is an $h\\times 1$ vector of constants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa0f9-f14c-432e-b11b-9709a221ea1e",
   "metadata": {},
   "source": [
    "The reasoning starts from $\\hat{\\beta}\\sim \\mathcal{N}(\\beta_0, \\sigma^2(X'X)^{-1})$. Hence, \n",
    "\n",
    "$$R\\hat{\\beta}-q \\sim \\mathcal{N}(0, \\sigma^2R(X'X)^{-1}R')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b039f97-0231-4700-b863-b473e9fde5a1",
   "metadata": {},
   "source": [
    "Because a multivariate normal distribution is harder to test. We compute a $\\chi^2$ statistics by normalizing $R\\hat{\\beta}-q$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05ad80-a88b-4e5b-b360-162c6ab3f489",
   "metadata": {},
   "source": [
    "$$Wald-statistic = (R\\beta-q)'[\\sigma^2R(X'X)^{-1}R']^{-1}(R\\beta-q)'$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa017da5-de1c-40b9-9fec-418882af92af",
   "metadata": {},
   "source": [
    "> This step is similar to $(\\frac{x-\\mu}{\\sigma})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317fd373-01fc-4739-97d4-25524292a9c4",
   "metadata": {},
   "source": [
    "And we have $Wald-statistics \\sim \\chi^2(h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131f64d-3895-4945-9553-abc033b8e022",
   "metadata": {},
   "source": [
    "### implement using smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b76818-e2e3-4d84-83a4-9333cdb78dca",
   "metadata": {},
   "source": [
    "Assume we want to test if $\\beta_1=1$ and $\\beta_2-\\beta_3=2$. We have h=2, and we can rewrite the restrictions as\n",
    "\n",
    "$$\\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & -1  \\end{bmatrix} \\beta - \\begin{bmatrix} 0 \\\\ 2  \\end{bmatrix}=0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9087b0a4-b2c3-40ec-bbca-f04e72fd3ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227564.92149323]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "wtest = res.wald_test(([[0,1,0,0],[0,0,1,-1]], [1,2]),use_f=False)\n",
    "print(wtest.statistic)\n",
    "print(wtest.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7764135f-83e6-40b8-9058-05fc69a22939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(227564.92149323)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra:\n",
    "# squeeze() removes axis with length 1. \n",
    "# In this example we have only one row, so there is no need to use a matrix\n",
    "wtest.statistic.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3394c79-5c4c-4d4b-81d3-7ca4d28f5cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<Wald test (chi2): statistic=[[227564.92149323]], p-value=0.0, df_denom=2>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a143a-55b3-478a-88e9-9b380594ceed",
   "metadata": {},
   "source": [
    "### implement using matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d5fc85-3d64-4c30-8311-276350582605",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[0,1,0,0],[0,0,1,-1]])\n",
    "q = np.array([1,2])\n",
    "b_h = res.params\n",
    "w = (R@b_h-q).T@np.linalg.inv(R@vcov@R.T)@(R@b_h-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "726fd374-9dc4-4c40-8fd5-20e04fc1d71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(227564.92149323)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d2ab3f9-87ba-4369-a19b-b64be2891a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8410396-6a04-4410-8786-98169f12e8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pvalue\n",
    "1-stats.chi2.cdf(w,df=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
